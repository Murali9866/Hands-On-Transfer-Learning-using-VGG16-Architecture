# -*- coding: utf-8 -*-
"""Transfer_Learning_Assignment22.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YJFu2XTk5IED19YfpDjsGnmDMXybfDeF

# Transfer Learning Assignment

Download all the data in this <a href='https://drive.google.com/open?id=1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu'>rar_file</a> , it contains all the data required for the assignment.
 When you unrar the file you'll get the files in the following format: <b>path/to/the/image.tif,category</b>
            
    where the categories are numbered 0 to 15, in the following order:
<pre>
    <b>0 letter
    1 form
    2 email
    3 handwritten
    4 advertisement
    5 scientific report
    6 scientific publication
    7 specification
    8 file folder
    9 news article
    10 budget
    11 invoice
    12 presentation
    13 questionnaire
    14 resume
    15 memo</b>
    
</pre>

There is a file named as 'labels_final.csv' , it consists of two columns. First column is path which is the required path to the images and second is the class label.
"""

#the dataset that you are dealing with is quite large 3.7 GB and hence there are two methods to import the data to Colab 
# Method 1- you can use gdown module to get the data directly from Google drive to Colab
# the syntax is as follows !gdown --id file_id , for ex - running the below cell will import the rvl-cdip.rar dataset

!gdown --id 1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu

# Method -2 you can also import the data using wget function
#https://www.youtube.com/watch?v=BPUfVq7RaY8

#unrar the file
get_ipython().system_raw("unrar x rvl-cdip.rar")

"""## 2. On this image data, you have to train 3 types of models as given below You have to split the data into Train and Validation data."""

#import all the required libraries
import tensorflow as tf
import os
import numpy as np
import pandas as pd

df=pd.read_csv('labels_final.csv',dtype=str)
df.head(1)

#preprocessed file final_x_csv
#import pandas as pd
#final_df=pd.read_csv('/content/preprocessed df.csv')

# Remove three columns as index base
#final_df.drop(final_df.columns[[0]], axis = 1, inplace = True)

#final_df.head(1)

"""3. Try not to load all the images into memory, use the gernarators that we have given the reference notebooks to load the batch of images only during the train data.
or you can use this method also
<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1</a>

<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c</a>

Note- In the reference notebook you were dealing with jpg images, in the given dataset you are dealing with tiff images. Imagedatagenrator works with both type of images. If you want to use custom data pipeline then you have to convert your tiff images to jpg images.

4. You are free to choose Learning rate, optimizer, loss function, image augmentation, any hyperparameters. but you have to use the same architechture what we are asking below. 

5. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)


6. You can check about Transfer Learning in this link - <a href='https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'>https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>

https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/3426/code-example-cats-vs-dogs/8/module-8-neural-networks-computer-vision-and-deep-learning </a>
</pre>

7. Do print model.summary() and draw model_plots for each of the model.

**ImageDataGenerator**
"""

import tensorflow as tf
import os
import numpy as np
import pandas as pd

dir_path = "/content/data_final"

#os.listdir(dir_path)

for i in os.listdir(dir_path):
    print("No of Images in ",i," category is ",len(os.listdir(os.path.join(dir_path,i))))

from keras_preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(rescale=1/224., validation_split=0.2) #image generator

#https://vijayabhaskar96.medium.com/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1
#https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator
#https://www.codegrepper.com/code-examples/python/keras+imagedatagenerator+train_test_split
image_generator = ImageDataGenerator(rescale=1/224, validation_split=0.2)    

train_generator = image_generator.flow_from_dataframe(dataframe=df, directory="/content/data_final", x_col="path", 
                                                    y_col="label", class_mode="categorical", 
                                                    target_size=(224,224), batch_size=32,subset='training')

validation_generator = image_generator.flow_from_dataframe(dataframe=df, directory="/content/data_final", x_col="path", 
                                                    y_col="label", class_mode="categorical", 
                                                    target_size=(224,224), batch_size=32,subset='validation')

#importing tensorflow
from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten
from tensorflow.keras.models import Model
import random as rn

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from keras.callbacks import Callback
from keras.callbacks import TensorBoard

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# Clear any logs from previous runs
!rm -rf ./logs/

import os
import tensorflow as tf
import datetime
log_dir = os.path.join("logs",'fits', datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=0,write_graph=True)

"""### Model-1

<pre>
1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights. 
2. After VGG-16 network without FC layers, add a new Conv block ( 1 Conv layer and 1 Maxpooling ), 2 FC layers and an output layer to classify 16 classes. You are free to choose any hyperparameters/parameters of conv block, FC layers, output layer. 
3. Final architecture will be <b>INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer</b>
4.Print model.summary() and plot the architecture of the model. 
<a href='https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model'>Reference for plotting model</a>
5. Train only new Conv block, FC layers, output layer. Don't train the VGG-16 network. 

</pre>
"""

#https://keras.io/guides/transfer_learning/
#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/
base_model = tf.keras.applications.vgg16.VGG16(
    weights="imagenet",  # Load weights pre-trained on ImageNet.
    input_shape=(224, 224, 3),
    include_top=False,
)  # Do not include the ImageNet classifier at the top.

base_model.summary()

#https://www.tensorflow.org/guide/keras/functional
#Adding custom Layers 
# Freeze the base_model
base_model.trainable = False
base_model1 = base_model.output
base_model1= tf.keras.layers.Conv2D(512,kernel_size=(2,2),padding="same",activation='relu')(base_model1)
#As the output of base model 7*7*512 i.e 512 kernels having 7*7 image size
#you need to match same number of kernels in new layer
#https://keras.io/api/layers/convolution_layers/convolution2d/

base_model1= tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same')(base_model1)
#https://keras.io/api/layers/pooling_layers/max_pooling2d/

base_model1= Flatten()(base_model1)
#Addding dense layers

#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense
base_model1 = tf.keras.layers.Dense(100,activation='relu')(base_model1)
base_model1=tf.keras.layers.Dense(200,activation='relu')(base_model1)
output = tf.keras.layers.Dense(16, activation="softmax")(base_model1)
# creating the final model 
model_1 = Model(inputs =base_model.input, outputs = output)
# compile the model 
model_1.compile(loss = "categorical_crossentropy", optimizer ='Adam', metrics=["accuracy"])

model_1.summary()

train_steps = train_generator.n//train_generator.batch_size
validation_steps = validation_generator.n//validation_generator.batch_size



#fitting the model_1
model_1.fit_generator(train_generator,steps_per_epoch=train_steps, epochs=5,verbose=1,
                              validation_data=validation_generator,validation_steps=validation_steps,callbacks=[tensorboard_callback])

#https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model
tf.keras.utils.plot_model(
    model_1,
    to_file='model_1.png',
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    layer_range=None,
    show_layer_activations=False
)



# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Observations:

1)Trainable Parameters of Model1 were reduced compared to base model, bcoz of fine tune the last layers with custom implementation of adding layers.

2)Accuracy of the model with each epoch was increased even fine tuning the last layers

### Model-2

<pre>
1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights.
2. After VGG-16 network without FC layers, don't use FC layers, use conv layers only as Fully connected layer.Any FC 
layer can be converted to a CONV layer. This conversion will reduce the No of Trainable parameters in FC layers. 
For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096. 
In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will
simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the 
initial FC layer. You can refer <a href='http://cs231n.github.io/convolutional-networks/#convert'>this</a> link to better understanding of using Conv layer in place of fully connected layers.
3. Final architecture will be VGG-16 without FC layers(without top), 2 Conv layers identical to FC layers, 1 output layer for 16 class classification. <b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC -->Output Layer</b>
4. 4.Print model.summary() and plot the architecture of the model. 
<a href='https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model'>Reference for plotting model</a>
5. Train only last 2 Conv layers identical to FC layers, 1 output layer. Don't train the VGG-16 network. 
</pre>
"""

!rm -rf ./logs/

"""#https://www.quora.com/How-do-I-transfer-fully-connected-layer-to-fully-convolutional-layers"""

#https://www.tensorflow.org/guide/keras/functional
for layer in base_model.layers:
    layer.trainable = False
##Adding custom Layers 
#model_1    
base_model1 = base_model.output

base_model1= tf.keras.layers.Conv2D(4096,kernel_size=(7,7),strides=1,activation='relu')(base_model1)
#As the output of base model 7*7*512 i.e 512 kernels having 7*7 image size
#you need to match same number of kernels in new layer
#https://keras.io/api/layers/convolution_layers/convolution2d/

base_model1=tf.keras.layers.Conv2D(4096,kernel_size=(1,1),strides=1,activation='relu')(base_model1) 
#https://keras.io/api/layers/pooling_layers/max_pooling2d/

base_model1= Flatten()(base_model1)
#Addding dense layers

#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense

output = tf.keras.layers.Dense(16, activation="softmax")(base_model1)
# creating the final model 
model_2 = Model(inputs =base_model.input, outputs = output)
# compile the model 
model_2.compile(loss = "categorical_crossentropy", optimizer ='Adam', metrics=["accuracy"])

model_2.summary()

#fitting the model_1
model_2.fit_generator(train_generator,steps_per_epoch=train_steps, epochs=5,verbose=1,
                              validation_data=validation_generator,validation_steps=validation_steps,
                      callbacks=[tensorboard_callback])

tf.keras.utils.plot_model(
    model_2,
    to_file='model_2.png',
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    layer_range=None,
    show_layer_activations=False
)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Observations:

1)Number of trainable parameters of Model_2 were increased compared to model_1.This is because of converting dense layers into conv layers having same number of parameters in dense layer.

2)Due to conversion of Dense into conv layers the model accuracy was decreased and computational time also increased.

### Model-3

<pre>
1. Use same network as Model-2 '<b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>' and train only Last 6 Layers of VGG-16 network, 2 Conv layers identical to FC layers, 1 output layer.
</pre>
"""

!rm -rf ./logs/

#https://classroom.appliedroots.com/v2/faqs/vkAgx07d/
#https://www.tensorflow.org/guide/keras/functional
#Adding custom Layers 
#model_1
for layer in base_model.layers[-6:]:
    layer.trainable = True
base_model1 = base_model.output
base_model1= tf.keras.layers.Conv2D(4096,kernel_size=(7,7),strides=1,activation='relu')(base_model1)
#As the output of base model 7*7*512 i.e 512 kernels having 7*7 image size
#you need to match same number of kernels in new layer
#https://keras.io/api/layers/convolution_layers/convolution2d/

base_model1=tf.keras.layers.Conv2D(4096,kernel_size=(1,1),strides=1,activation='relu')(base_model1) 
#https://keras.io/api/layers/pooling_layers/max_pooling2d/

base_model1= Flatten()(base_model1)
#Addding dense layers

#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense

output = tf.keras.layers.Dense(16, activation="softmax")(base_model1)
# creating the final model 
model_3 = Model(inputs =base_model.input, outputs = output)
# compile the model 
model_3.compile(loss = "categorical_crossentropy", optimizer ='Adam', metrics=["accuracy"])

model_3.summary()

#fitting model_3
model_3.fit_generator(train_generator,steps_per_epoch=train_steps, epochs=5,
                              validation_data=validation_generator,validation_steps=validation_steps,callbacks=[tensorboard_callback])

tf.keras.utils.plot_model(
    model_3,
    to_file='model_3.png',
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    layer_range=None,
    show_layer_activations=False
)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Observations:

1)In earlier models because of the freezing of weights except top layers the trainable parameters compared to model 3 were decreased,but in model 3 itself we retrain the last 6 layers so the number of trainable parameters were increased and the accuracy of the model also decreased

2)if you want high accuracy then increase number of epochs of the model since rise in no of trainable parameters.
"""